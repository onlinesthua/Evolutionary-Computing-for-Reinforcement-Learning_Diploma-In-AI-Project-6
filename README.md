This project focuses on using Evolutionary Computing techniques to solve reinforcement learning problems. Evolutionary Computing encompasses a range of optimization algorithms inspired by the process of natural selection, such as Genetic Algorithms (GAs). The project will implement GAs from scratch and integrate them into an RL environment to simulate evolution.

By implementing the core components of genetic algorithms, participants will gain insight into how population-based optimization methods can be applied to RL tasks. They will explore concepts such as selection, crossover, and mutation to evolve solutions that maximize cumulative rewards in a given environment.

Potential uses:
1.	Optimization Problems: Solving complex optimization problems in various domains, such as scheduling, routing, or resource allocation.
2.	Robotics: Evolving control policies for robotic agents to perform tasks in dynamic environments.
3.	Game Playing: Evolving strategies for playing board games or video games through repeated simulations and selection pressures.

Learning outcomes:
1.	Understanding of genetic algorithms and their application in reinforcement learning.
2.	Proficiency in implementing key components of genetic algorithms using Python.
3.	Ability to integrate genetic algorithms into RL environments and analyze the performance of evolved solutions.

This project is prepared by Chen Yijie under the supervision of Zhou Changxin.
